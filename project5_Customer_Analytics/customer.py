# -*- coding: utf-8 -*-
"""Customer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZPgQaCd20iSMElvpoPSEXn6o408G3MiK

# **Import Necessary Libraries**
"""

!pip install mlflow

!pip install keras_tuner

!pip install mlflow pyngrok --quiet

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, classification_report , auc
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score

from tensorflow.keras import models, layers
from imblearn.over_sampling import SMOTE

import joblib
import mlflow
import mlflow.sklearn
from tensorflow.keras.models import load_model
import tempfile

from sklearn.model_selection import RandomizedSearchCV

# For Saving the Model
from joblib import dump , load

from keras_tuner.tuners import RandomSearch
import gradio

"""# **Load the dataset**"""

customer = pd.read_csv("/content/customer_churn.csv")

customer.head()

"""# **Data Inspection**"""

#shows all the columns available
pd.set_option("display.max_columns", None)
pd.set_option("display.expand_frame_repr",False)
pd.set_option("max_colwidth",None)

## Preview of Data
customer.head(4)

# Basic Info about the dataset
customer.info()

# Summary Statistics for the numercial columns
customer.describe()

# Summary Statistics for the categorical columns
customer.describe(include=['object', 'category'])

# Shape of the data
customer.shape

# To get all the column names
customer.columns

# Checking if any null values are there:
customer.isnull().sum()

# Checking if any duplicate values  are there :
print(f'{customer.duplicated().sum()}')

"""# **DATA MANIPULATION**"""

# Extract the 5th column and store it in ‘customer_5’
customer_5 = customer.iloc[:,4]
customer_5

# Extract the 15th column and store it in ‘customer_15’
customer_15 = customer.iloc[:,14]
customer_15

# Extract all the male senior citizens whose payment method is electronic check and store the result in ‘senior_male_electronic’

senior_male_electronic = customer[(customer['gender'] == 'Male') & (customer['PaymentMethod'] == 'Electronic check' )]
senior_male_electronic.head(3)

# Extract all those customers whose tenure is greater than 70 months or their monthly charges is more than $100 and store the result in
# ‘customer_total_tenure’

customer_total_tenure = customer[(customer['tenure'] > 70 ) | (customer['MonthlyCharges'] > 100.0 )]
customer_total_tenure.head(2)

# Extract all the customers whose contract is of two years, payment method is mailed check and the value of churn is ‘Yes’ and store the result in
# ‘two_mail_yes’

two_mail_yes = customer[(customer['Contract'] == 'Two year') & (customer['PaymentMethod'] == 'Mailed check') & (customer['Churn'] == 'Yes' )]
two_mail_yes.head(2)

# Extract 333 random records from the customer_churndataframe and store
# the result in ‘customer_333’

customer_333 = customer.sample(333)

#Get the count of different levels from the ‘Churn’ column
churn_count = customer['Churn'].value_counts()
churn_count

"""# **Visualization**"""

plt.figure(figsize=(10,6))
sns.countplot(data=customer,x='Churn',color='orange')
plt.title("Churn Distribution")
plt.xlabel("Churn : 1 = Yes & 0 = No")
plt.show()

plt.figure(figsize=(10,6))
sns.countplot(data=customer,x='InternetService', hue = 'Churn',palette = 'Set2')
plt.title("Churn by Internet Services")
plt.show()

plt.figure(figsize=(10,6))
sns.countplot(data=customer,x='gender', hue = 'Churn',palette = 'Set1')
plt.title("Churn by Gender")
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(data=customer, x= 'tenure', hue = 'Churn',bins=10 )
plt.title("Distribution of Tenure by Churn")
plt.xlabel("Tenure")
plt.show()

plt.figure(figsize=(10,6))
sns.boxplot(data=customer, x = 'Churn' , y = 'MonthlyCharges', color = 'orange')
plt.title("Monthly Charges by Churn")
plt.show()

# Model wont understand the categorical columns so we need to do encoding :

# To get all the categorical columns along with all unique values present in it.
for col in customer.columns :
    if customer[col].dtypes == 'object' :
        print(f"{col} : {customer[col].unique()}")

# As total charges is a numerical col we need to remove it from the object
customer['TotalCharges'] = pd.to_numeric(customer['TotalCharges'],errors = 'coerce')

print(customer['TotalCharges'].isnull().sum())

customer.dropna(inplace=True)

print(customer['TotalCharges'].isnull().sum())

# Intializing the Label Encoding
le = LabelEncoder()

for col in customer.columns :
    if customer[col].dtypes == 'object' :
        customer[col] = le.fit_transform(customer[col])
        print(le.classes_)

customer.head(2)

"""# **Feature Engineering using RFE:**"""

suggested_features = ['SeniorCitizen','tenure','DeviceProtection','TechSupport','Contract','TotalCharges',
                      'PaymentMethod','MonthlyCharges','StreamingMovies','Partner','InternetService'
                     ]

X = customer[suggested_features]
y= customer['Churn']

# To implement random forest classifier as a baseline model for RFE:
rfc = RandomForestClassifier(n_estimators=110 , random_state = 3)

# initializing the RFE:
rfe = RFE(estimator = rfc , n_features_to_select = 6) #top n features to select for further analysis.
# Fit the rfe :
rfe.fit(X,y)

selected_features = [feature for feature, selected in zip(suggested_features , rfe.support_) if selected]
print(f'The Selected Features are : {selected_features}')

# fit the randomforestclassifier
rfc.fit(X,y)


imporatnces = pd.DataFrame({'feature':suggested_features, 'importance': rfc.feature_importances_})
imporatnces = imporatnces.sort_values('importance', ascending=False)
imporatnces

#plot
plt.figure(figsize=(8,8))
sns.barplot(x='importance', y='feature', data=imporatnces)
plt.title("Feature importance")

"""# **Defining X and Y variables and Train test split**"""

X = customer[selected_features]
y = customer['Churn']

# Splitting the data into train and test set
X_train , X_test , y_train , y_test = train_test_split( X , y , test_size = 0.2 , random_state = 42)

# Scailing
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# **Appyling Logistics Regression on imbalanced dataset**"""

# Intializing the model :
Lrs = LogisticRegression(max_iter=100)

# Train the model using fit
Lrs.fit(X_train_scaled,y_train)

# Testing of the model/prediction
y_pred_lor = Lrs.predict(X_test_scaled)

# To evaluate how model is performing
print(f'Accuracy Score : {accuracy_score(y_test,y_pred_lor)}')
print("\n",f'The Classification Report : ')
print("\n", classification_report(y_test, y_pred_lor))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_lor), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of Logistic Regression")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""# **Training Using XGBoost on Imbalanced dataset**"""

# Initializing the model
xgb_cls = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')

# Train the model using fit
xgb_cls.fit(X_train_scaled, y_train)

# Testing of the model/prediction
y_pred_xgb = xgb_cls.predict(X_test_scaled)

# To evaluate how model is performing
print(f'Accuracy Score : {accuracy_score(y_test,y_pred_xgb)}')
print("\n",f'The Classification Report : ')
print("\n", classification_report(y_test,y_pred_xgb))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of XGBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
y_pred_proba = xgb_cls.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve : Using XGBoost Classifier")
plt.legend()
plt.show()

"""# **Appyling Smote and Training Logistics Regression Models**"""

# Applying Smote as data is not balanced :
# Oversampling
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

# Building a Logistics Regression model:

# Intializing the model :
Lrs = LogisticRegression(max_iter=100)

# Train the model using fit
Lrs.fit(X_train_smote,y_train_smote)

# Testing of the model/prediction
y_pred = Lrs.predict(X_test_scaled)

# To evaluate how model is performing
print(f'Accuracy Score : {accuracy_score(y_test,y_pred)}')
print("\n",f'The Classification Report : ')
print("\n", classification_report(y_test, y_pred))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of Logistic Regression")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
y_pred_proba = Lrs.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve : Using Logistic Regression")
plt.legend()
plt.show()

"""# **Decision Tree Classifier**"""

# intializing the model :
dtc = DecisionTreeClassifier()

# Train the model using fit
dtc.fit(X_train_smote,y_train_smote)

# Testing of the model/prediction
y_pred_dtc = dtc.predict(X_test_scaled)

# To evaluate how model is performing
print(f'Accuracy Score : {accuracy_score(y_test,y_pred_dtc)}')
print("\n",f'The Classification Report : ')
print("\n", classification_report(y_test, y_pred_dtc))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_dtc), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of Decision Tree")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
y_pred_proba_dtc = dtc.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba_dtc)
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve : Using Decision Tree")
plt.legend()

plt.tight_layout()
plt.show()

"""# **Training Using Random Forest**"""

# Intializing the model :
rfc = RandomForestClassifier()

# Train the model using fit
rfc.fit(X_train_smote,y_train_smote)

# Testing of the model/prediction
y_pred_rfc = rfc.predict(X_test_scaled)

# To evaluate how model is performing
print(f'Accuracy Score : {accuracy_score(y_test,y_pred_rfc)}')
print("\n",f'The Classification Report : ')
print("\n", classification_report(y_test, y_pred_rfc))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_rfc), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
y_pred_proba_rfc = rfc.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba_rfc)
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve : Using Random Forest")
plt.legend()
plt.show()

"""# **XGBoost Classifier**"""

# Initializing the model
xgb_cls = XGBClassifier(eval_metric='mlogloss')

# Train the model using fit
xgb_cls.fit(X_train_smote, y_train_smote)

# Testing of the model/prediction
y_pred_xgb = xgb_cls.predict(X_test_scaled)

# To evaluate how model is performing
print(f'Accuracy Score : {accuracy_score(y_test,y_pred_xgb)}')
print("\n",f'The Classification Report : ')
print("\n", classification_report(y_test,y_pred_xgb))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of XGBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
y_pred_proba_xgb = xgb_cls.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba_xgb)
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve : Using XGBoost")
plt.legend()
plt.show()

"""# **Feed Forward Neural Network**"""

def create_model(hp=None):
    model = models.Sequential()

    if hp:
        # First hidden layer
        model.add(layers.Dense(
            units=hp.Choice('label_1', values=[32, 64, 128]),
            activation='relu',
            input_shape=(X_train_smote.shape[1],)
        ))

        # Optional second hidden layer
        if hp.Boolean('second_layer'):
            model.add(layers.Dense(
                units=hp.Choice('label_2', values=[16, 32]),
                activation='relu'
            ))

        # Output layer
        model.add(layers.Dense(1, activation='sigmoid'))

        # Compile model
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
    else:
        # Default model without hyperparameter tuning
        model = models.Sequential([
            layers.Dense(64, activation='relu', input_shape=(X_train_smote.shape[1],)),
            layers.Dense(32, activation='relu'),
            layers.Dense(16, activation='relu'),
            layers.Dense(8, activation='relu'),
            layers.Dense(1, activation='sigmoid')
        ])

        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

    return model

# Building the Neural Network :

# without passing hp :
first_model = create_model()

# run nn and give certain number of epoch running
history = first_model.fit(
    X_train_smote,
    y_train_smote,
    epochs= 150,
    batch_size=32,
    validation_split=0.20,
    verbose=1
)

print(first_model.summary())

"""# **Predict & Evaluate Using Confusion Matrix**"""

# Predict classes on test set
y_pred = (first_model.predict(X_test_scaled) > 0.5).astype("int32")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay


# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("Confusion Matrix - Neural Network")
plt.show()

loss, accuracy = first_model.evaluate(X_test_scaled, y_test)
print(f"Test Loss : {loss}")
print(f"Test Accuracy : {accuracy}")

# Plot visual data of loss
plt.figure(figsize=(16,8)) #sizing the canvas
plt.subplot(1,2,1) # (row,col,which position plot will come in)to show plot side by side
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel("Loss")
plt.title("Model Loss Curve")
plt.legend()
plt.grid(alpha=0.3)

# To Plot the Accuracy :
plt.figure(figsize=(16,8)) #sizing the canvas
plt.subplot(1,2,2) # plot will be on 2nd position
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel("Accuracy")
plt.title("Model Accuracy Curve")
plt.legend()
plt.grid(alpha=0.3)

"""# **Saving all the Trained Model**

Saving Scaler and RFE
"""

joblib.dump(scaler, "scaler.pkl")
joblib.dump(rfe, "rfe_selector.pkl")

"""# Classifier Models:"""

# Logistics Regression
dump(Lrs , 'logistics_regression_model.pkl')

# Decision Tree
dump(dtc , 'decision_tree_model.pkl')

# Random Forest
dump(rfc, 'random_forest_model.pkl')

"""# Feed Forward Neural Network"""

first_model.save('ffnn_model.h5')

"""# **Customer Segmentation**"""

X_fetures_seg = customer[[
    'tenure' ,
    'MonthlyCharges' ,
    'TotalCharges',
    'SeniorCitizen',
    'Contract',
    'PaymentMethod'
 ]]

# Applying Standard Scaler :
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_fetures_seg)

"""# **K-Means**"""

# Find the Optimal number of cluster using Elbow Method
ssd = []
cluster = range(1,11)

for i in cluster :
    model_clus =  KMeans(n_clusters = i , max_iter = 150 , random_state = 42) # creating kmeans model forrach k values
    model_clus.fit(X_scaled)
    ssd.append(model_clus.inertia_)

# Plot
plt.figure(figsize=(12,4))
plt.plot(cluster, ssd , 'bo-')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method : To Choose Optimal K')
plt.show()

# Silhoutte score

clusters = range(2, 11)
for k in clusters :
    model_clus =  KMeans(n_clusters = k, max_iter = 150 , random_state = 42)
    model_clus.fit(X_scaled)
    cluster_labels = model_clus.labels_ # making cluster labels
    s_score = silhouette_score(X_scaled,cluster_labels)
    print(k, s_score)

# K-Means Clustering
kmeans = KMeans(n_clusters = 4,
                random_state = 42)

kmeans.fit(X_scaled)

cluster_labels = kmeans.labels_
customer['Cluster'] = cluster_labels

"""### Saving the Cluster Labels Dataset"""

# Save Trained Model
dump(kmeans , "customer_Segmenatation_model.pkl")

dump(scaler , "customer_segmentation_scaler.pkl")

"""# **DBSCAN**"""

# To choose eps Using K-distance graph:
neighbors = NearestNeighbors(n_neighbors = 5)
neighbors = neighbors.fit(X_scaled)
distances , indices = neighbors.kneighbors(X_scaled)

distances = np.sort(distances[:, 4])
plt.plot(distances)
plt.show()

dbscan = DBSCAN(eps = 0.9 , min_samples = 5 )

dbscan.fit(X_scaled)

dbscan_labels = dbscan.labels_
customer['DBSCAN_Cluster'] = dbscan_labels

# Saving the Model
dump(dbscan , "customer_seg_DBSCAN.pkl")

# Comparing cluster count:
print(customer['DBSCAN_Cluster'].value_counts())

# PCA for 2D Visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

customer['PCA1'] = X_pca[:, 0]
customer['PCA2'] = X_pca[:, 1]

# Plot KMeans
plt.figure(figsize=(8,4))
sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=customer, palette='Set1')
plt.title("KMeans Clustering (PCA Reduced)")
plt.show()

# Plot DBSCAN
plt.figure(figsize=(8,4))
sns.scatterplot(x='PCA1', y='PCA2', hue='DBSCAN_Cluster', data=customer, palette='Set2')
plt.title("DBSCAN Clustering (PCA Reduced)")
plt.legend().set_visible(False)
plt.show()

"""# **Customer Segmentation Insights**

- **KMeans** found 4 clear segments based on charges, contract type, and tenure.
- **DBSCAN** failed to form meaningful clusters — too many small groups.
- It matters: because it helps target at-risk customers with offers and improve retention.

# **Tracking through ML Flow**
"""

import shutil
shutil.rmtree("mlruns")

import os
from pyngrok import ngrok

# Set MLflow to log to local file system
os.environ["MLFLOW_TRACKING_URI"] = "file:///C:/Users/aparn/Downloads/mlrun"

# Start the MLflow tracking UI on port 5000
#get_ipython().system_raw("mlflow ui --port 5000 &")

!ngrok config add-authtoken "3056lIUVu1PaNKDAbZeluKmDvbc_2SGC3Vh1ckMLybi5w83gK"

# Start the MLflow tracking UI on port 5000
get_ipython().system_raw("mlflow ui --backend-store-uri file:///C:/Users/aparn/Downloads/mlrun --port 5000 &")

# Get ngrok URL
public_url = ngrok.connect(5000)
print(f"MLflow UI: {public_url}")

"""# **Logging All ML Models in ML-Flow**"""

# Define models and names
models = {
    "Logistic Regression": Lrs,
    "Decision Tree": dtc,
    "Random Forest": rfc,
    "XGBoost": xgb_cls
}
mlflow.set_tracking_uri("file:///C:/Users/aparn/Downloads/mlrun")
mlflow.set_experiment("Customer Churn Models")

for name, model in models.items():
    print(f"Logging {name} to MLflow...")

    # Predict
    y_pred = model.predict(X_test_scaled)

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    cm = confusion_matrix(y_test, y_pred)

    with mlflow.start_run(run_name=name):

        # Log model
        mlflow.sklearn.log_model(model, artifact_path="model")

        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision", report['weighted avg']['precision'])
        mlflow.log_metric("recall", report['weighted avg']['recall'])
        mlflow.log_metric("f1_score", report['weighted avg']['f1-score'])

        # Confusion Matrix Plot
        plt.figure(figsize=(5, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title(f"Confusion Matrix - {name}")
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
            plt.savefig(tmp.name)
            mlflow.log_artifact(tmp.name, artifact_path="plots")
            plt.close()

        # ROC Curve (only for models with predict_proba)
        if hasattr(model, "predict_proba"):
            y_prob = model.predict_proba(X_test_scaled)[:, 1]
            fpr, tpr, _ = roc_curve(y_test, y_prob)
            plt.figure(figsize=(6, 4))
            plt.plot(fpr, tpr, label="ROC Curve")
            plt.plot([0, 1], [0, 1], 'k--')
            plt.xlabel("False Positive Rate")
            plt.ylabel("True Positive Rate")
            plt.title(f"ROC Curve - {name}")
            plt.legend()
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
                plt.savefig(tmp.name)
                mlflow.log_artifact(tmp.name, artifact_path="plots")
                plt.close()

    print(f"Logged {name} successfully.\n")

"""# **Logging FFNN**"""

# Start MLflow logging
with mlflow.start_run(run_name="FFNN Logging"):

    # Evaluate metrics
    loss, accuracy = first_model.evaluate(X_test_scaled, y_test)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Log metrics
    mlflow.log_metric("test_loss", loss)
    mlflow.log_metric("test_accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)
    mlflow.log_metric("f1_score", f1)

    # Log model
    mlflow.tensorflow.log_model(first_model, artifact_path="FFNN_model")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title("Confusion Matrix - Neural Network")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        plt.savefig(tmp.name)
        plt.close()
        mlflow.log_artifact(tmp.name, artifact_path="plots")
    #Accuracy :
    plt.figure(figsize=(16,8)) #sizing the canvas
    plt.subplot(1,2,2) # plot will be on 2nd position
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel("Accuracy")
    plt.title("Model Accuracy Curve")
    plt.legend()
    plt.grid(alpha=0.3)
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        plt.savefig(tmp.name)
        plt.close()
        mlflow.log_artifact(tmp.name, artifact_path="plots")



    # ROC Curve
    y_pred_prob = first_model.predict(X_test_scaled).ravel()
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plt.figure()
    plt.plot(fpr, tpr, label="ROC Curve")
    plt.plot([0, 1], [0, 1], 'k--')
    plt.title("ROC Curve: FFNN")
    plt.legend()
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
      plt.savefig(tmp.name)
      plt.close()
      mlflow.log_artifact(tmp.name, artifact_path="plots")

    print("✅ FFNN logs saved to MLflow.")

"""# **Logging K-Means and DBSCAN**"""

with mlflow.start_run(run_name="KMeans Clustering"):

    # Log Parameters
    mlflow.log_param("KMeans_n_clusters", 4)

    # Silhouette Score
    kmeans_score = silhouette_score(X_scaled, customer['Cluster'])
    mlflow.log_metric("KMeans_silhouette_score", kmeans_score)

    # Elbow Plot
    plt.figure(figsize=(8, 4))
    plt.plot(range(1, 11), ssd, 'bo-')
    plt.xlabel('Number of Clusters')
    plt.ylabel('Inertia')
    plt.title('Elbow Method')
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        plt.savefig(tmp.name)
        plt.close()
        mlflow.log_artifact(tmp.name, artifact_path="plots")

    # Silhouette Scores for K = 2 to 10
    sil_scores = []
    for k in range(2, 11):
        km = KMeans(n_clusters=k, random_state=42)
        km.fit(X_scaled)
        score = silhouette_score(X_scaled, km.labels_)
        sil_scores.append(score)

    plt.figure(figsize=(8, 4))
    plt.plot(range(2, 11), sil_scores, 'go-')
    plt.xlabel("Clusters")
    plt.ylabel("Silhouette Score")
    plt.title("Silhouette Scores by Cluster Count")
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        plt.savefig(tmp.name)
        plt.close()
        mlflow.log_artifact(tmp.name, artifact_path="plots")

    # PCA Scatter Plot for KMeans
    plt.figure(figsize=(8, 4))
    sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=customer, palette='Set1')
    plt.title("KMeans Clustering (PCA Reduced)")
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        plt.savefig(tmp.name)
        plt.close()
        mlflow.log_artifact(tmp.name, artifact_path="plots")

    print("✅ KMeans clustering logged to MLflow.")

with mlflow.start_run(run_name="DBSCAN Clustering"):

    # Log Parameters
    mlflow.log_param("DBSCAN_eps", 0.9)
    mlflow.log_param("DBSCAN_min_samples", 5)

    # Silhouette Score
    dbscan_labels = customer['DBSCAN_Cluster']
    if len(set(dbscan_labels)) > 1 and -1 in dbscan_labels:
        valid_labels = dbscan_labels[dbscan_labels != -1]
        valid_X = X_scaled[dbscan_labels != -1]
        score = silhouette_score(valid_X, valid_labels)
        mlflow.log_metric("DBSCAN_silhouette_score (no noise)", score)

    # PCA Scatter Plot for DBSCAN
    plt.figure(figsize=(8, 4))
    sns.scatterplot(x='PCA1', y='PCA2', hue='DBSCAN_Cluster', data=customer, palette='Set2')
    plt.title("DBSCAN Clustering (PCA Reduced)")
    plt.legend().set_visible(False)
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        plt.savefig(tmp.name)
        plt.close()
        mlflow.log_artifact(tmp.name, artifact_path="plots")

    print("✅ DBSCAN clustering logged to MLflow.")

"""# **Hyper-Parameter Tuning**

Logistics Regression
"""

param_grid = [
    {  # l2 penalty with lbfgs or liblinear
        'penalty': ['l2'],
        'solver': ['lbfgs', 'liblinear'],
        'C': np.logspace(-3, 2, 10),
    },
    {  # l1 penalty with liblinear
        'penalty': ['l1'],
        'solver': ['liblinear'],
        'C': np.logspace(-3, 2, 10),
    },
    {  # elasticnet with saga only
        'penalty': ['elasticnet'],
        'solver': ['saga'],
        'l1_ratio': [0.3, 0.5, 0.7],  # required for elasticnet
        'C': np.logspace(-3, 2, 10),
    }
]

lr = LogisticRegression(max_iter=1000)

random_search_lor = RandomizedSearchCV(
    estimator=lr,
    param_distributions=param_grid,
    n_iter=50,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

random_search_lor.fit(X_train_smote, y_train_smote)

print("Best Accuracy From Logistics Regression after using Random Serach : ",random_search_lor.best_score_)
print("Best Parameters From Logistics Regression after using Random Serach : ",random_search_lor.best_params_)

# Default or baseline model prediction
y_pred_proba_base = Lrs.predict_proba(X_test_scaled)[:, 1]
fpr_base, tpr_base, _ = roc_curve(y_test, y_pred_proba_base)
auc_base = auc(fpr_base, tpr_base)

# Best model from RandomizedSearchCV
best_model = random_search_lor.best_estimator_
y_pred_proba_best = best_model.predict_proba(X_test_scaled)[:, 1]
fpr_best, tpr_best, _ = roc_curve(y_test, y_pred_proba_best)
auc_best = auc(fpr_best, tpr_best)

# Plot both ROC curves
plt.figure(figsize=(8, 6))
plt.plot(fpr_base, tpr_base, label=f"Base Logistic Regression (AUC = {auc_base:.2f})", linestyle='--')
plt.plot(fpr_best, tpr_best, label=f"Tuned Logistic Regression (AUC = {auc_best:.2f})", linestyle='-')
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')

# Labels and styling
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Predictions
y_pred_base = Lrs.predict(X_test_scaled)
y_pred_tuned = best_model.predict(X_test_scaled)

# Reports
print("Base Model Report:\n", classification_report(y_test, y_pred_base))
print("Tuned Model Report:\n", classification_report(y_test, y_pred_tuned))

"""**Logistic Regression Tunned Model into ML Flow**"""

with mlflow.start_run(run_name = "Logistics Regression tuned Random search"):
  best_model = random_search_lor.best_estimator_
  mlflow.sklearn.log_model(best_model , "log_reg_tuned_random_models")
  mlflow.log_params(random_search_lor.best_params_)
  mlflow.log_metric("best_accuracy" , random_search_lor.best_score_)
  print("Random Search Tuned Logistics Regression Model logged with ML-Flow")

"""# **Random Forest**"""

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'max_features': ['sqrt', 'log2', None],
    'min_samples_split': [2, 4, 6],
    'min_samples_leaf': [1, 2, 4]
}

rf = RandomForestClassifier(random_state = 42)

random_search_rf = RandomizedSearchCV(
    estimator = rf,
    param_distributions = param_grid,
    n_iter = 20,
    cv = 5,
    verbose = 2,
    n_jobs = -1,
    random_state = 42
)

random_search_rf.fit(X_train_smote, y_train_smote)
print("Best Parameters:", random_search_rf.best_params_)
print("Best Accuracy:", random_search_rf.best_score_)

joblib.dump(random_search_rf , "random_forest_tunned.pkl")

joblib.dump(random_search_rf , "random_forest_tuned_compressed.z", compress=3)

"""**Random Forest Tunned Model into ML Flow**"""

with mlflow.start_run(run_name="Random Forest tuned Random search"):
    best_model = random_search_rf.best_estimator_
    mlflow.sklearn.log_model(best_model, "random_forest_tuned_random_models")
    mlflow.log_params(random_search_rf.best_params_)
    mlflow.log_metric("best_accuracy", random_search_rf.best_score_)
    print("Random Search Tuned Random Forest Model logged with ML-Flow")

from scipy.stats import randint, uniform

# Define base model
xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)

# Define hyperparameter distributions
param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': randint(3, 10),
    'learning_rate': uniform(0.01, 0.3),
    'subsample': uniform(0.6, 0.4),
    'colsample_bytree': uniform(0.6, 0.4)
}

# Setup RandomizedSearchCV
random_search_xgb = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_dist,
    n_iter=25,
    scoring='accuracy',
    cv=5,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# Fit on training data
random_search_xgb.fit(X_train_smote, y_train_smote)

# Best parameters and model
print("✅ Best Parameters:", random_search_xgb.best_params_)
best_xgb = random_search_xgb.best_estimator_

# Evaluate
y_pred_xgb = best_xgb.predict(X_test_scaled)
print("\n Classification Report:\n", classification_report(y_test, y_pred_xgb))

print("Best Accuracy From XGboost after using Random Search : ",random_search_xgb.best_score_)
print("Best Parameters From XGBoost Regression after using Random Search : ",random_search_xgb.best_params_)

print("Best Accuracy:", random_search_xgb.best_score_)

joblib.dump(random_search_rf , "XGBoost_tunned.pkl")

joblib.dump(random_search_rf , "XGBoost_tuned_compressed.z", compress=3)

with mlflow.start_run(run_name="XGBoost tuned Random search"):
    best_model = random_search_xgb.best_estimator_
    mlflow.xgboost.log_model(
        best_model,
        artifact_path="xgb_model",
        registered_model_name="XGBoost_Tuned"
    )
    mlflow.log_params(random_search_xgb.best_params_)
    mlflow.log_metric("best_accuracy", random_search_xgb.best_score_)
    print("Random Search Tuned XGBoost Model logged with MLflow")

mlflow.xgboost.log_model(
    xgb_model,
    artifact_path="xgb_model",
    registered_model_name="XGBoost Tuned"
)

"""**Tuning FFNN**"""

from tensorflow.keras import models
from tensorflow.keras import layers

tuner = RandomSearch(
    create_model,
    objective = 'val_accuracy',
    max_trials = 10,
    executions_per_trial = 1,
    directory = 'ffnn-tuning',
    project_name = 'Customer Churn'
)


tuner.search(X_train_smote ,
             y_train_smote,
             epochs = 20,
             validation_split = 0.2,
             batch_size = 32)

# For getting the best model:
best = tuner.get_best_hyperparameters(num_trials = 1)[0]
best_model_fnn = tuner.hypermodel.build(best)

# Re-training
best_model_fnn.fit(X_train_smote ,
                   y_train_smote ,
                   epochs = 20,
                   validation_split = 0.2)

best_model_fnn.save("FFNN_Tuned_Model.h5")

mlflow.tensorflow.autolog()

with mlflow.start_run(run_name = "FFNN_Tuned"):
  mlflow.log_param("unit_layer1" , best.get('label_1'))
  mlflow.log_param("unit_layer2" , best.get('label_2'))
  mlflow.log_param("second_layer" , best.get('second_layer'))


# Log metrics:
  val_accuracy = best_model_fnn.evaluate(X_train_smote,
                                   y_train_smote,
                                   verbose = 0)[1]

  mlflow.keras.log_model(best_model_fnn, "FFNN_Tuned_Model")

  print("Best Model FFNN Tunned logged with ML Flow")

joblib.dump(rfe, "rfe_selector_compressed.z", compress=3)

"""# **Gradio Integration**"""

scaler.feature_names_in_

import gradio as gr

def predict_churn(
    senior_citizen, tenure, device_protection, tech_support,
    contract, total_charges, payment_method, monthly_charges,
    streaming_movies, partner, internet_service
):
    try:
        # Step 1: Manual encodings to match training
        label_maps = {
            'DeviceProtection': {'No': 0, 'Yes': 1},
            'TechSupport': {'No': 0, 'Yes': 1},
            'Contract': {'Month-to-month': 0, 'One year': 1, 'Two year': 2},
            'PaymentMethod': {
                'Electronic check': 0, 'Mailed check': 1,
                'Bank transfer (automatic)': 2, 'Credit card (automatic)': 3
            },
            'StreamingMovies': {'No': 0, 'Yes': 1},
            'Partner': {'No': 0, 'Yes': 1},
            'InternetService': {'DSL': 0, 'Fiber optic': 1, 'No': 2}
        }

        row = {
            'SeniorCitizen': int(senior_citizen),
            'tenure': float(tenure),
            'DeviceProtection': label_maps['DeviceProtection'][device_protection],
            'TechSupport': label_maps['TechSupport'][tech_support],
            'Contract': label_maps['Contract'][contract],
            'TotalCharges': float(total_charges),
            'PaymentMethod': label_maps['PaymentMethod'][payment_method],
            'MonthlyCharges': float(monthly_charges),
            'StreamingMovies': label_maps['StreamingMovies'][streaming_movies],
            'Partner': label_maps['Partner'][partner],
            'InternetService': label_maps['InternetService'][internet_service]
        }

        # Step 2: Build full input in correct order
        df = pd.DataFrame([row])[[
            'SeniorCitizen','tenure','DeviceProtection','TechSupport','Contract','TotalCharges',
            'PaymentMethod','MonthlyCharges','StreamingMovies','Partner','InternetService'
        ]]

        # Step 3: RFE transform
        selected = rfe.transform(df)

        # Step 4: Scale the selected features
        scaled = scaler.transform(selected)

        # Step 5: Predict
        prediction = random_search_xgb.predict(scaled)[0]

        return "❌ Churn" if prediction == 1 else "✅ Not Churn"

    except Exception as e:
        return f"⚠️ Error: {str(e)}"

demo = gr.Interface(
    fn=predict_churn,
    inputs=[
        gr.Checkbox(label="Senior Citizen"),
        gr.Number(label="Tenure"),
        gr.Dropdown(['No', 'Yes'], label="Device Protection"),
        gr.Dropdown(['No', 'Yes'], label="Tech Support"),
        gr.Dropdown(['Month-to-month', 'One year', 'Two year'], label="Contract"),
        gr.Number(label="Total Charges"),
        gr.Dropdown(['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'], label="Payment Method"),
        gr.Number(label="Monthly Charges"),
        gr.Dropdown(['No', 'Yes'], label="Streaming Movies"),
        gr.Dropdown(['No', 'Yes'], label="Partner"),
        gr.Dropdown(['DSL', 'Fiber optic', 'No'], label="Internet Service")
    ],
    outputs="text",
    title="📉 Customer Churn Predictor",
    description="11-input model RFE + scaler + Trained and Tuned XGBoost"
)

demo.launch()

"""# **Logged Gradio App**"""

gradio_code = '''
import gradio as gr
import pickle
import numpy as np
import pandas as pd

# Load saved components
with open("XGBoost_tunned.pkl", "rb") as f:
    model = pickle.load(f)
with open("scaler.pkl", "rb") as f:
    scaler = pickle.load(f)
with open("rfe_selector.pkl", "rb") as f:
    rfe = pickle.load(f)

def predict_churn(
    senior_citizen, tenure, device_protection, tech_support,
    contract, total_charges, payment_method, monthly_charges,
    streaming_movies, partner, internet_service
):
    try:
        # Step 1: Manual encodings to match training
        label_maps = {
            'DeviceProtection': {'No': 0, 'Yes': 1},
            'TechSupport': {'No': 0, 'Yes': 1},
            'Contract': {'Month-to-month': 0, 'One year': 1, 'Two year': 2},
            'PaymentMethod': {
                'Electronic check': 0, 'Mailed check': 1,
                'Bank transfer (automatic)': 2, 'Credit card (automatic)': 3
            },
            'StreamingMovies': {'No': 0, 'Yes': 1},
            'Partner': {'No': 0, 'Yes': 1},
            'InternetService': {'DSL': 0, 'Fiber optic': 1, 'No': 2}
        }

        row = {
            'SeniorCitizen': int(senior_citizen),
            'tenure': float(tenure),
            'DeviceProtection': label_maps['DeviceProtection'][device_protection],
            'TechSupport': label_maps['TechSupport'][tech_support],
            'Contract': label_maps['Contract'][contract],
            'TotalCharges': float(total_charges),
            'PaymentMethod': label_maps['PaymentMethod'][payment_method],
            'MonthlyCharges': float(monthly_charges),
            'StreamingMovies': label_maps['StreamingMovies'][streaming_movies],
            'Partner': label_maps['Partner'][partner],
            'InternetService': label_maps['InternetService'][internet_service]
        }

        # Step 2: Build full input in correct order
        df = pd.DataFrame([row])[[
            'SeniorCitizen','tenure','DeviceProtection','TechSupport','Contract','TotalCharges',
            'PaymentMethod','MonthlyCharges','StreamingMovies','Partner','InternetService'
        ]]

        # Step 3: RFE transform
        selected = rfe.transform(df)

        # Step 4: Scale the selected features
        scaled = scaler.transform(selected)

        # Step 5: Predict
        prediction = random_search_xgb.predict(scaled)[0]

        return "❌ Churn" if prediction == 1 else "✅ Not Churn"

    except Exception as e:
        return f"⚠️ Error: {str(e)}"

demo = gr.Interface(
    fn=predict_churn,
    inputs=[
        gr.Checkbox(label="Senior Citizen"),
        gr.Number(label="Tenure"),
        gr.Dropdown(['No', 'Yes'], label="Device Protection"),
        gr.Dropdown(['No', 'Yes'], label="Tech Support"),
        gr.Dropdown(['Month-to-month', 'One year', 'Two year'], label="Contract"),
        gr.Number(label="Total Charges"),
        gr.Dropdown(['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'], label="Payment Method"),
        gr.Number(label="Monthly Charges"),
        gr.Dropdown(['No', 'Yes'], label="Streaming Movies"),
        gr.Dropdown(['No', 'Yes'], label="Partner"),
        gr.Dropdown(['DSL', 'Fiber optic', 'No'], label="Internet Service")
    ],
    outputs="text",
    title="📉 Customer Churn Predictor",
    description="11-input model with RFE + scaler + Trained and Tuned XGBoost"
)

demo.launch()
'''

# Save to a .py file
with open("app.py", "w") as f:
    f.write(gradio_code)

from google.colab import files
uploaded = files.upload()

with mlflow.start_run(run_name="Gradio App"):
    mlflow.log_artifact("gradio_app.py", artifact_path="gradio_ui")
    mlflow.log_artifact("Gradio UI.png", artifact_path="gradio_ui")
    mlflow.set_tag("Gradio_App_URL", "https://74210d45131a11131e.gradio.live/")
    print("✅ Gradio app saved and logged.")

# To get txt file
!pip freeze > requirements.txt